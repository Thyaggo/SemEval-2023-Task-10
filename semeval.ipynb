{"cells":[{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/sgarc/SemEval/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]},{"name":"stdout","output_type":"stream","text":["tr version 4.35.1\n","Using device =>  cpu  torch  2.1.0+cu121\n"]}],"source":["import os\n","import transformers\n","from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup, RobertaModel, RobertaTokenizer\n","import torch\n","from torch import nn, optim\n","from torch.utils.data import Dataset, DataLoader, TensorDataset\n","from torch.nn.utils.rnn import pad_sequence\n","import torch.nn.functional as F\n","from torch.utils.tensorboard import SummaryWriter\n","import numpy as np\n","import pandas as pd\n","from sklearn.metrics import confusion_matrix, classification_report\n","import tqdm\n","import matplotlib.pyplot as plt\n","from collections import Counter\n","import pickle\n","import re\n","import copy\n","import pprint\n","import time\n","\n","MAX_NO_OF_SPEAKERS = 8\n","MAX_DIALOGUE_LEN   = 33\n","original_labels    = ['abuse', 'adoration', 'annoyance', 'awkwardness', 'benefit', 'boredom', 'calmness', 'challenge', 'cheer', 'confusion', 'curiosity', 'desire', 'excitement', 'guilt', 'horror', 'humour', 'impressed', 'loss', 'nervousness', 'nostalgia', 'pain', 'relief', 'satisfaction', 'scold', 'shock', 'sympathy', 'threat']\n","train_count        = [31, 190, 1051, 880, 220, 78, 752, 214, 534, 486, 545, 180, 867, 216, 280, 153, 257, 351, 398, 65, 36, 173, 136, 94, 372, 209, 263]\n","\n","EMOTIONS           = ['anger', 'disgust', 'fear', 'joy', 'neutral', 'sadness', 'surprise']\n","\n","sent_model = 'roberta-base-nli-stsb-mean-tokens'\n","\n","print('tr version', transformers.__version__)\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(\"Using device => \",device, ' torch ', torch.__version__)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-11-14T16:06:19.592349Z","iopub.status.busy":"2023-11-14T16:06:19.592071Z","iopub.status.idle":"2023-11-14T16:06:29.220772Z","shell.execute_reply":"2023-11-14T16:06:29.219872Z","shell.execute_reply.started":"2023-11-14T16:06:19.592324Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["model loaded\n"]}],"source":["class EmotionClassifier(nn.Module):\n","    def __init__(self, n_classes):\n","        super(EmotionClassifier, self).__init__()\n","        self.bert = RobertaModel.from_pretrained('roberta-base')\n","        self.drop = nn.Dropout(p=0.3)\n","        self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n","    def forward(self, input_ids, attention_mask):\n","        op = self.bert(input_ids=input_ids,attention_mask=attention_mask)\n","        output = self.drop(op[1])\n","        return self.out(output), op[1]\n","\n","# load finetuned roberta model\n","roberta_tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n","roberta_finetuned = EmotionClassifier(7).to(device)\n","#roberta_tf_checkpoint = torch.load('dump_files/finetuned/best_model_state_roberta.bin', map_location=torch.device(device))\n","#roberta_finetuned.load_state_dict(roberta_tf_checkpoint)\n","print('model loaded')\n","\n","\n","# Helper functions\n","\n"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-11-14T16:06:29.222235Z","iopub.status.busy":"2023-11-14T16:06:29.221960Z","iopub.status.idle":"2023-11-14T16:06:29.444188Z","shell.execute_reply":"2023-11-14T16:06:29.443408Z","shell.execute_reply.started":"2023-11-14T16:06:29.222211Z"},"trusted":true},"outputs":[],"source":["train_csv = pd.read_json(\"EDiReF-Train-Data/Task 3/MELD_train_efr.json\")"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-11-14T16:06:29.460576Z","iopub.status.busy":"2023-11-14T16:06:29.460285Z","iopub.status.idle":"2023-11-14T16:06:29.465753Z","shell.execute_reply":"2023-11-14T16:06:29.464909Z","shell.execute_reply.started":"2023-11-14T16:06:29.460552Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>episode</th>\n","      <th>speakers</th>\n","      <th>emotions</th>\n","      <th>utterances</th>\n","      <th>triggers</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>utterance_0</td>\n","      <td>[Chandler, The Interviewer, Chandler, The Inte...</td>\n","      <td>[neutral, neutral, neutral, neutral, surprise]</td>\n","      <td>[also I was the point person on my company's t...</td>\n","      <td>[0.0, 0.0, 0.0, 1.0, 0.0]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>utterance_1</td>\n","      <td>[Chandler, The Interviewer, Chandler, The Inte...</td>\n","      <td>[neutral, neutral, neutral, neutral, surprise,...</td>\n","      <td>[also I was the point person on my company's t...</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>utterance_2</td>\n","      <td>[Chandler, The Interviewer, Chandler, The Inte...</td>\n","      <td>[neutral, neutral, neutral, neutral, surprise,...</td>\n","      <td>[also I was the point person on my company's t...</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>utterance_3</td>\n","      <td>[Chandler, The Interviewer, Chandler, The Inte...</td>\n","      <td>[neutral, neutral, neutral, neutral, surprise,...</td>\n","      <td>[also I was the point person on my company's t...</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>utterance_4</td>\n","      <td>[Joey, Rachel, Joey, Rachel]</td>\n","      <td>[surprise, sadness, surprise, fear]</td>\n","      <td>[But then who? The waitress I went out with la...</td>\n","      <td>[0.0, 0.0, 1.0, 0.0]</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>3995</th>\n","      <td>utterance_3995</td>\n","      <td>[Chandler, All, Monica, Chandler, Ross, Chandl...</td>\n","      <td>[neutral, joy, neutral, neutral, surprise, dis...</td>\n","      <td>[Hey., Hey!, So how was Joan?, I broke up with...</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>3996</th>\n","      <td>utterance_3996</td>\n","      <td>[Chandler, All, Monica, Chandler, Ross, Chandl...</td>\n","      <td>[neutral, joy, neutral, neutral, surprise, dis...</td>\n","      <td>[Hey., Hey!, So how was Joan?, I broke up with...</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>3997</th>\n","      <td>utterance_3997</td>\n","      <td>[Chandler, All, Monica, Chandler, Ross, Chandl...</td>\n","      <td>[neutral, joy, neutral, neutral, surprise, dis...</td>\n","      <td>[Hey., Hey!, So how was Joan?, I broke up with...</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>3998</th>\n","      <td>utterance_3998</td>\n","      <td>[Chandler, All, Monica, Chandler, Ross, Chandl...</td>\n","      <td>[neutral, joy, neutral, neutral, surprise, dis...</td>\n","      <td>[Hey., Hey!, So how was Joan?, I broke up with...</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>3999</th>\n","      <td>utterance_3999</td>\n","      <td>[Chandler, All, Monica, Chandler, Ross, Chandl...</td>\n","      <td>[neutral, joy, neutral, neutral, surprise, dis...</td>\n","      <td>[Hey., Hey!, So how was Joan?, I broke up with...</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>4000 rows × 5 columns</p>\n","</div>"],"text/plain":["             episode                                           speakers  \\\n","0        utterance_0  [Chandler, The Interviewer, Chandler, The Inte...   \n","1        utterance_1  [Chandler, The Interviewer, Chandler, The Inte...   \n","2        utterance_2  [Chandler, The Interviewer, Chandler, The Inte...   \n","3        utterance_3  [Chandler, The Interviewer, Chandler, The Inte...   \n","4        utterance_4                       [Joey, Rachel, Joey, Rachel]   \n","...              ...                                                ...   \n","3995  utterance_3995  [Chandler, All, Monica, Chandler, Ross, Chandl...   \n","3996  utterance_3996  [Chandler, All, Monica, Chandler, Ross, Chandl...   \n","3997  utterance_3997  [Chandler, All, Monica, Chandler, Ross, Chandl...   \n","3998  utterance_3998  [Chandler, All, Monica, Chandler, Ross, Chandl...   \n","3999  utterance_3999  [Chandler, All, Monica, Chandler, Ross, Chandl...   \n","\n","                                               emotions  \\\n","0        [neutral, neutral, neutral, neutral, surprise]   \n","1     [neutral, neutral, neutral, neutral, surprise,...   \n","2     [neutral, neutral, neutral, neutral, surprise,...   \n","3     [neutral, neutral, neutral, neutral, surprise,...   \n","4                   [surprise, sadness, surprise, fear]   \n","...                                                 ...   \n","3995  [neutral, joy, neutral, neutral, surprise, dis...   \n","3996  [neutral, joy, neutral, neutral, surprise, dis...   \n","3997  [neutral, joy, neutral, neutral, surprise, dis...   \n","3998  [neutral, joy, neutral, neutral, surprise, dis...   \n","3999  [neutral, joy, neutral, neutral, surprise, dis...   \n","\n","                                             utterances  \\\n","0     [also I was the point person on my company's t...   \n","1     [also I was the point person on my company's t...   \n","2     [also I was the point person on my company's t...   \n","3     [also I was the point person on my company's t...   \n","4     [But then who? The waitress I went out with la...   \n","...                                                 ...   \n","3995  [Hey., Hey!, So how was Joan?, I broke up with...   \n","3996  [Hey., Hey!, So how was Joan?, I broke up with...   \n","3997  [Hey., Hey!, So how was Joan?, I broke up with...   \n","3998  [Hey., Hey!, So how was Joan?, I broke up with...   \n","3999  [Hey., Hey!, So how was Joan?, I broke up with...   \n","\n","                                               triggers  \n","0                             [0.0, 0.0, 0.0, 1.0, 0.0]  \n","1                   [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]  \n","2     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...  \n","3     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n","4                                  [0.0, 0.0, 1.0, 0.0]  \n","...                                                 ...  \n","3995  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n","3996  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n","3997  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n","3998  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n","3999  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n","\n","[4000 rows x 5 columns]"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["train_df = pd.DataFrame(train_csv)\n","train_df"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-11-14T16:06:29.467119Z","iopub.status.busy":"2023-11-14T16:06:29.466837Z","iopub.status.idle":"2023-11-14T16:06:29.475801Z","shell.execute_reply":"2023-11-14T16:06:29.474939Z","shell.execute_reply.started":"2023-11-14T16:06:29.467097Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["['neutral', 'neutral', 'neutral', 'neutral', 'surprise'] ['Chandler', 'The Interviewer', 'Chandler', 'The Interviewer', 'Chandler']\n"]}],"source":["print(train_df['emotions'][0], train_df['speakers'][0])"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-11-14T16:06:29.477471Z","iopub.status.busy":"2023-11-14T16:06:29.477156Z","iopub.status.idle":"2023-11-14T16:06:29.495667Z","shell.execute_reply":"2023-11-14T16:06:29.494870Z","shell.execute_reply.started":"2023-11-14T16:06:29.477441Z"},"trusted":true},"outputs":[{"data":{"text/plain":["0     True\n","1    False\n","2    False\n","3    False\n","4    False\n","5    False\n","6    False\n","Name: anger, dtype: bool"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["dummies = pd.get_dummies(EMOTIONS)\n","dummies['anger']"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-11-14T16:06:29.497013Z","iopub.status.busy":"2023-11-14T16:06:29.496741Z","iopub.status.idle":"2023-11-14T16:06:29.672035Z","shell.execute_reply":"2023-11-14T16:06:29.671283Z","shell.execute_reply.started":"2023-11-14T16:06:29.496987Z"},"trusted":true},"outputs":[],"source":["listaEmo = []\n","for i in train_df['emotions']:\n","    listtemp = []\n","    for j in i:\n","        listtemp.append(dummies[j])\n","    listaEmo.append(listtemp)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>1st Customer</th>\n","      <th>2nd Customer</th>\n","      <th>3rd Customer</th>\n","      <th>A Female Student</th>\n","      <th>A Student</th>\n","      <th>Alice</th>\n","      <th>All</th>\n","      <th>Allesandro</th>\n","      <th>Angela</th>\n","      <th>Annabelle</th>\n","      <th>...</th>\n","      <th>Tour Guide</th>\n","      <th>Trudie Styler</th>\n","      <th>Ursula</th>\n","      <th>Voice</th>\n","      <th>Waiter</th>\n","      <th>Wayne</th>\n","      <th>Woman</th>\n","      <th>Woman On Train</th>\n","      <th>Young Ethan</th>\n","      <th>an</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>...</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>...</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>...</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>...</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>...</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>226</th>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>...</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>227</th>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>...</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>228</th>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>...</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>229</th>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>...</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>230</th>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>...</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>231 rows × 231 columns</p>\n","</div>"],"text/plain":["     1st Customer  2nd Customer  3rd Customer  A Female Student  A Student  \\\n","0            True         False         False             False      False   \n","1           False          True         False             False      False   \n","2           False         False          True             False      False   \n","3           False         False         False              True      False   \n","4           False         False         False             False       True   \n","..            ...           ...           ...               ...        ...   \n","226         False         False         False             False      False   \n","227         False         False         False             False      False   \n","228         False         False         False             False      False   \n","229         False         False         False             False      False   \n","230         False         False         False             False      False   \n","\n","     Alice    All  Allesandro  Angela  Annabelle  ...  Tour Guide  \\\n","0    False  False       False   False      False  ...       False   \n","1    False  False       False   False      False  ...       False   \n","2    False  False       False   False      False  ...       False   \n","3    False  False       False   False      False  ...       False   \n","4    False  False       False   False      False  ...       False   \n","..     ...    ...         ...     ...        ...  ...         ...   \n","226  False  False       False   False      False  ...       False   \n","227  False  False       False   False      False  ...       False   \n","228  False  False       False   False      False  ...       False   \n","229  False  False       False   False      False  ...       False   \n","230  False  False       False   False      False  ...       False   \n","\n","     Trudie Styler  Ursula  Voice  Waiter  Wayne  Woman  Woman On Train  \\\n","0            False   False  False   False  False  False           False   \n","1            False   False  False   False  False  False           False   \n","2            False   False  False   False  False  False           False   \n","3            False   False  False   False  False  False           False   \n","4            False   False  False   False  False  False           False   \n","..             ...     ...    ...     ...    ...    ...             ...   \n","226          False   False  False   False   True  False           False   \n","227          False   False  False   False  False   True           False   \n","228          False   False  False   False  False  False            True   \n","229          False   False  False   False  False  False           False   \n","230          False   False  False   False  False  False           False   \n","\n","     Young Ethan     an  \n","0          False  False  \n","1          False  False  \n","2          False  False  \n","3          False  False  \n","4          False  False  \n","..           ...    ...  \n","226        False  False  \n","227        False  False  \n","228        False  False  \n","229         True  False  \n","230        False   True  \n","\n","[231 rows x 231 columns]"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["listSpk = []\n","for i in train_df['speakers']:\n","    for j in i:\n","        if j in listSpk:\n","            continue\n","        else:\n","            listSpk.append(j)\n","listSpk.sort()\n","speaker_specific = pd.get_dummies(listSpk)\n","speaker_specific"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["listasp = []\n","for i in train_df['speakers']:\n","    listatemp = []\n","    for j in i:\n","        listatemp.append(speaker_specific[j])\n","    listasp.append(listatemp)"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>episode</th>\n","      <th>speakers</th>\n","      <th>emotions</th>\n","      <th>utterances</th>\n","      <th>triggers</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>utterance_0</td>\n","      <td>[[False, False, False, False, False, False, Fa...</td>\n","      <td>[neutral, neutral, neutral, neutral, surprise]</td>\n","      <td>[also I was the point person on my company's t...</td>\n","      <td>[0.0, 0.0, 0.0, 1.0, 0.0]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>utterance_1</td>\n","      <td>[[False, False, False, False, False, False, Fa...</td>\n","      <td>[neutral, neutral, neutral, neutral, surprise,...</td>\n","      <td>[also I was the point person on my company's t...</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>utterance_2</td>\n","      <td>[[False, False, False, False, False, False, Fa...</td>\n","      <td>[neutral, neutral, neutral, neutral, surprise,...</td>\n","      <td>[also I was the point person on my company's t...</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>utterance_3</td>\n","      <td>[[False, False, False, False, False, False, Fa...</td>\n","      <td>[neutral, neutral, neutral, neutral, surprise,...</td>\n","      <td>[also I was the point person on my company's t...</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>utterance_4</td>\n","      <td>[[False, False, False, False, False, False, Fa...</td>\n","      <td>[surprise, sadness, surprise, fear]</td>\n","      <td>[But then who? The waitress I went out with la...</td>\n","      <td>[0.0, 0.0, 1.0, 0.0]</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>3995</th>\n","      <td>utterance_3995</td>\n","      <td>[[False, False, False, False, False, False, Fa...</td>\n","      <td>[neutral, joy, neutral, neutral, surprise, dis...</td>\n","      <td>[Hey., Hey!, So how was Joan?, I broke up with...</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>3996</th>\n","      <td>utterance_3996</td>\n","      <td>[[False, False, False, False, False, False, Fa...</td>\n","      <td>[neutral, joy, neutral, neutral, surprise, dis...</td>\n","      <td>[Hey., Hey!, So how was Joan?, I broke up with...</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>3997</th>\n","      <td>utterance_3997</td>\n","      <td>[[False, False, False, False, False, False, Fa...</td>\n","      <td>[neutral, joy, neutral, neutral, surprise, dis...</td>\n","      <td>[Hey., Hey!, So how was Joan?, I broke up with...</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>3998</th>\n","      <td>utterance_3998</td>\n","      <td>[[False, False, False, False, False, False, Fa...</td>\n","      <td>[neutral, joy, neutral, neutral, surprise, dis...</td>\n","      <td>[Hey., Hey!, So how was Joan?, I broke up with...</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>3999</th>\n","      <td>utterance_3999</td>\n","      <td>[[False, False, False, False, False, False, Fa...</td>\n","      <td>[neutral, joy, neutral, neutral, surprise, dis...</td>\n","      <td>[Hey., Hey!, So how was Joan?, I broke up with...</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>4000 rows × 5 columns</p>\n","</div>"],"text/plain":["             episode                                           speakers  \\\n","0        utterance_0  [[False, False, False, False, False, False, Fa...   \n","1        utterance_1  [[False, False, False, False, False, False, Fa...   \n","2        utterance_2  [[False, False, False, False, False, False, Fa...   \n","3        utterance_3  [[False, False, False, False, False, False, Fa...   \n","4        utterance_4  [[False, False, False, False, False, False, Fa...   \n","...              ...                                                ...   \n","3995  utterance_3995  [[False, False, False, False, False, False, Fa...   \n","3996  utterance_3996  [[False, False, False, False, False, False, Fa...   \n","3997  utterance_3997  [[False, False, False, False, False, False, Fa...   \n","3998  utterance_3998  [[False, False, False, False, False, False, Fa...   \n","3999  utterance_3999  [[False, False, False, False, False, False, Fa...   \n","\n","                                               emotions  \\\n","0        [neutral, neutral, neutral, neutral, surprise]   \n","1     [neutral, neutral, neutral, neutral, surprise,...   \n","2     [neutral, neutral, neutral, neutral, surprise,...   \n","3     [neutral, neutral, neutral, neutral, surprise,...   \n","4                   [surprise, sadness, surprise, fear]   \n","...                                                 ...   \n","3995  [neutral, joy, neutral, neutral, surprise, dis...   \n","3996  [neutral, joy, neutral, neutral, surprise, dis...   \n","3997  [neutral, joy, neutral, neutral, surprise, dis...   \n","3998  [neutral, joy, neutral, neutral, surprise, dis...   \n","3999  [neutral, joy, neutral, neutral, surprise, dis...   \n","\n","                                             utterances  \\\n","0     [also I was the point person on my company's t...   \n","1     [also I was the point person on my company's t...   \n","2     [also I was the point person on my company's t...   \n","3     [also I was the point person on my company's t...   \n","4     [But then who? The waitress I went out with la...   \n","...                                                 ...   \n","3995  [Hey., Hey!, So how was Joan?, I broke up with...   \n","3996  [Hey., Hey!, So how was Joan?, I broke up with...   \n","3997  [Hey., Hey!, So how was Joan?, I broke up with...   \n","3998  [Hey., Hey!, So how was Joan?, I broke up with...   \n","3999  [Hey., Hey!, So how was Joan?, I broke up with...   \n","\n","                                               triggers  \n","0                             [0.0, 0.0, 0.0, 1.0, 0.0]  \n","1                   [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]  \n","2     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...  \n","3     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n","4                                  [0.0, 0.0, 1.0, 0.0]  \n","...                                                 ...  \n","3995  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n","3996  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n","3997  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n","3998  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n","3999  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n","\n","[4000 rows x 5 columns]"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["train_df['speakers'] = listasp\n","train_df"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2023-11-14T16:06:29.802230Z","iopub.status.busy":"2023-11-14T16:06:29.801452Z","iopub.status.idle":"2023-11-14T16:07:18.894222Z","shell.execute_reply":"2023-11-14T16:07:18.893211Z","shell.execute_reply.started":"2023-11-14T16:06:29.802200Z"},"trusted":true},"outputs":[],"source":["i = 0\n","sentence_embeddings = []\n","    # sent_emb = model.encode('')\n","while i < len(train_df):\n","    utt = train_df['utterances'][i]\n","    encodings = roberta_tokenizer.encode_plus(utt, max_length=100, padding = 'max_length', add_special_tokens=True, return_token_type_ids=True, return_attention_mask=True, truncation=True, return_tensors='pt').to(device)\n","    utt_emb = roberta_finetuned(encodings['input_ids'], encodings['attention_mask'])[1].detach().tolist()[0]\n","    utt_emb = np.round(utt_emb, decimals = 10)\n","    # utt_emb = model.encode(utt)\n","    sent_emb = utt_emb\n","    i += 1\n","    sentence_embeddings.append(copy.deepcopy(sent_emb))\n"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2023-11-14T16:07:18.900062Z","iopub.status.busy":"2023-11-14T16:07:18.899761Z","iopub.status.idle":"2023-11-14T16:07:20.219604Z","shell.execute_reply":"2023-11-14T16:07:20.218823Z","shell.execute_reply.started":"2023-11-14T16:07:18.900037Z"},"trusted":true},"outputs":[],"source":["train_df['sentence_embeddings'] = sentence_embeddings\n","df_sent = pd.DataFrame(sentence_embeddings)"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2023-11-14T16:07:20.221010Z","iopub.status.busy":"2023-11-14T16:07:20.220720Z","iopub.status.idle":"2023-11-14T16:07:20.257434Z","shell.execute_reply":"2023-11-14T16:07:20.256631Z","shell.execute_reply.started":"2023-11-14T16:07:20.220985Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["           Valence  Arousal  Dominance\n","aaaaaaah     0.479    0.606      0.291\n","aaaah        0.520    0.636      0.282\n","aardvark     0.427    0.490      0.437\n","aback        0.385    0.407      0.288\n","abacus       0.510    0.276      0.485\n","...            ...      ...        ...\n","zoo          0.760    0.520      0.580\n","zoological   0.667    0.458      0.492\n","zoology      0.568    0.347      0.509\n","zoom         0.490    0.520      0.462\n","zucchini     0.510    0.321      0.250\n","\n","[19971 rows x 3 columns]\n"]}],"source":["csvread = pd.read_csv(\"./EDiReF-Train-Data/Task 3/out.csv\",names=[\"Valence\", \"Arousal\", \"Dominance\"])\n","print(csvread)"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2023-11-14T16:07:20.259187Z","iopub.status.busy":"2023-11-14T16:07:20.258489Z","iopub.status.idle":"2023-11-14T16:10:25.727400Z","shell.execute_reply":"2023-11-14T16:10:25.726609Z","shell.execute_reply.started":"2023-11-14T16:07:20.259163Z"},"trusted":true},"outputs":[],"source":["import re\n","from collections import defaultdict\n","\n","track = defaultdict(list)\n","\n","for i in train_df['utterances']:\n","    for sentence in i:\n","        sentence = sentence.lower().split()\n","        for word in sentence:\n","            cleaned_word = re.sub(r'[^a-zA-Z]', '', word)\n","            if cleaned_word in csvread.index and cleaned_word not in track:\n","                track[cleaned_word].append(csvread['Valence'][cleaned_word])\n","                track[cleaned_word].append(csvread['Arousal'][cleaned_word])\n","                track[cleaned_word].append(csvread['Dominance'][cleaned_word])\n","                \n","\n","# Ahora, track contendrá las palabras limpias como claves y listas de diccionarios como valores, \n","# donde cada diccionario contiene las propiedades Valence, Arousal y Dominance para esa palabra.\n"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2023-11-14T16:10:25.811361Z","iopub.status.busy":"2023-11-14T16:10:25.811026Z","iopub.status.idle":"2023-11-14T16:10:26.829379Z","shell.execute_reply":"2023-11-14T16:10:26.828591Z","shell.execute_reply.started":"2023-11-14T16:10:25.811331Z"},"trusted":true},"outputs":[],"source":["valen = []\n","aros = []\n","domi = []\n","for i in train_df['utterances']:\n","    listVal = []\n","    listAro = []\n","    listDom = []\n","    for sentence in i:\n","        valence_sen = []\n","        arousal_sen = []\n","        dominance_sen = []\n","        sentence = sentence.lower().split()\n","        for word in sentence:\n","            cleaned_word = re.sub(r'[^a-zA-Z]', '', word)\n","            if cleaned_word in track:\n","                val, aro, dom = track[cleaned_word]\n","                valence_sen.append(float(val))\n","                arousal_sen.append(float(aro))\n","                dominance_sen.append(float(dom))\n","            else:\n","                valence_sen.append(0)\n","                arousal_sen.append(0)\n","                dominance_sen.append(0)\n","        listVal.append(valence_sen)\n","        listAro.append(arousal_sen)\n","        listDom.append(dominance_sen)\n","    valen.append(listVal)\n","    aros.append(listAro)\n","    domi.append(listDom)"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2023-11-14T16:10:26.843222Z","iopub.status.busy":"2023-11-14T16:10:26.842944Z","iopub.status.idle":"2023-11-14T16:10:27.342890Z","shell.execute_reply":"2023-11-14T16:10:27.341959Z","shell.execute_reply.started":"2023-11-14T16:10:26.843190Z"},"trusted":true},"outputs":[],"source":["meanT = []\n","for i in valen:\n","    mean = []\n","    for j in i:\n","        mean.append(np.mean(j))\n","    meanT.append(mean)"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2023-11-14T16:16:34.031493Z","iopub.status.busy":"2023-11-14T16:16:34.031157Z","iopub.status.idle":"2023-11-14T16:16:34.038656Z","shell.execute_reply":"2023-11-14T16:16:34.037717Z","shell.execute_reply.started":"2023-11-14T16:16:34.031468Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[[0], [0], [0, 0, 0, 0], [0, 0.245, 0, 0, 0], [0, 0.551, 0, 0, 0, 0, 0.802, 0.396, 0.449], [0, 0, 0.573, 0, 0, 0, 0, 0, 0, 0, 0], [0.529, 0, 0, 0, 0, 0, 0.573], [0, 0, 0, 0, 0.57, 0.438, 0, 0, 0.635, 0, 0.667], [0, 0, 0, 0.823, 0, 0, 0, 0, 0.06, 0, 0, 0, 0.357, 0.083, 0.519], [0.448, 0, 0.448, 0], [0, 0, 0.439, 0, 0.51, 0, 0, 0.542], [0, 0, 0.625, 0, 0, 0, 0.847, 0, 0, 0, 0, 0.806, 0, 0.49, 0, 0, 0, 0, 0.49, 0.958, 0.844, 0, 0, 0, 0, 0, 0, 0.811], [0, 0, 0, 0.594], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0.757, 0, 0], [0, 0, 0, 0, 0, 0, 0.74], [0]]\n"]},{"data":{"text/plain":["['Hey.',\n"," 'Hey!',\n"," 'So how was Joan?',\n"," 'I broke up with her.',\n"," \"Don't tell me, because of the big nostril thing?\",\n"," 'They were huge. When she sneezed, bats flew out of them.',\n"," 'Come on, they were not that huge.',\n"," \"I'm tellin' you, she leaned back; I could see her brain.\",\n"," 'How many perfectly fine women are you gonna reject over the most superficial insignificant things?',\n"," 'Hold it, hold it.',\n"," 'I gotta side with Chandler on this one.',\n"," \"When I first moved to the city, I went out a couple of times with this girl, really hot, great kisser, but she had the biggest Adam's apple.\",\n"," 'It made me nuts.',\n"," 'You or me?',\n"," \"I got it. Uh, Joey, women don't have Adam's apples.\",\n"," 'You guys are messing with me, right?',\n"," 'Yeah.']"]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["print(valen[3999])\n","train_df['utterances'][3999]"]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2023-11-14T20:26:21.260686Z","iopub.status.busy":"2023-11-14T20:26:21.259816Z","iopub.status.idle":"2023-11-14T20:26:21.266129Z","shell.execute_reply":"2023-11-14T20:26:21.265120Z","shell.execute_reply.started":"2023-11-14T20:26:21.260653Z"},"trusted":true},"outputs":[],"source":["train_df['valence'] = meanT"]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2023-11-14T16:10:27.363832Z","iopub.status.busy":"2023-11-14T16:10:27.362915Z","iopub.status.idle":"2023-11-14T16:10:27.375483Z","shell.execute_reply":"2023-11-14T16:10:27.374630Z","shell.execute_reply.started":"2023-11-14T16:10:27.363801Z"},"trusted":true},"outputs":[{"data":{"text/plain":["array([nan, nan,  5., nan, nan])"]},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":["nanlist = np.full(len(meanT[0]), np.nan)\n","nanlist[2] = 5\n","nanlist"]},{"cell_type":"code","execution_count":44,"metadata":{"execution":{"iopub.execute_input":"2023-11-14T18:04:19.837008Z","iopub.status.busy":"2023-11-14T18:04:19.836150Z","iopub.status.idle":"2023-11-14T18:04:19.946830Z","shell.execute_reply":"2023-11-14T18:04:19.945961Z","shell.execute_reply.started":"2023-11-14T18:04:19.836975Z"},"trusted":true},"outputs":[],"source":["import copy\n","lista = []\n","\n","for i in range(len(train_df['speakers'])):\n","    diccionario = {}\n","    nanlist = np.full(len(meanT[i]), np.nan)\n","    \n","    for j, speaker in enumerate(train_df['speakers'][i]):\n","        if speaker in diccionario:\n","            diccionario[speaker][j] = meanT[i][j]\n","        else:\n","            nanlist_copy = copy.copy(nanlist)  # Crea una copia independiente de nanlist\n","            nanlist_copy[j] = meanT[i][j]\n","            diccionario[speaker] = nanlist_copy\n","\n","    lista.append(list(diccionario.values()))\n","\n"]},{"cell_type":"code","execution_count":45,"metadata":{"execution":{"iopub.execute_input":"2023-11-14T18:12:09.405386Z","iopub.status.busy":"2023-11-14T18:12:09.404664Z","iopub.status.idle":"2023-11-14T18:12:09.528413Z","shell.execute_reply":"2023-11-14T18:12:09.527705Z","shell.execute_reply.started":"2023-11-14T18:12:09.405353Z"},"trusted":true},"outputs":[],"source":["replaced_valance = [np.nan_to_num(x, nan=-1) for x in lista]\n","train_df['valence_speaker']=replaced_valance"]},{"cell_type":"code","execution_count":46,"metadata":{"execution":{"iopub.execute_input":"2023-11-14T18:12:45.518020Z","iopub.status.busy":"2023-11-14T18:12:45.517288Z","iopub.status.idle":"2023-11-14T18:12:45.525033Z","shell.execute_reply":"2023-11-14T18:12:45.524183Z","shell.execute_reply.started":"2023-11-14T18:12:45.517988Z"},"trusted":true},"outputs":[{"data":{"text/plain":["array([[ 0.19283333, -1.        ,  0.412875  , -1.        , -1.        ,\n","        -1.        , -1.        , -1.        , -1.        ,  0.14285714,\n","        -1.        ,  0.255     , -1.        , -1.        ],\n","       [-1.        ,  0.501125  , -1.        , -1.        , -1.        ,\n","         0.        , -1.        ,  0.170125  , -1.        , -1.        ,\n","         0.        , -1.        , -1.        ,  0.32129412],\n","       [-1.        , -1.        , -1.        ,  0.1855    , -1.        ,\n","        -1.        , -1.        , -1.        , -1.        , -1.        ,\n","        -1.        , -1.        , -1.        , -1.        ],\n","       [-1.        , -1.        , -1.        , -1.        ,  0.27875   ,\n","        -1.        ,  0.40166667, -1.        , -1.        , -1.        ,\n","        -1.        , -1.        , -1.        , -1.        ],\n","       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n","        -1.        , -1.        , -1.        ,  0.4185    , -1.        ,\n","        -1.        , -1.        ,  0.2858    , -1.        ]])"]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["train_df['valence_speaker'][174]"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-11-14T20:26:27.018924Z","iopub.status.busy":"2023-11-14T20:26:27.018087Z","iopub.status.idle":"2023-11-14T20:26:27.127066Z","shell.execute_reply":"2023-11-14T20:26:27.126146Z","shell.execute_reply.started":"2023-11-14T20:26:27.018877Z"},"trusted":true},"outputs":[{"ename":"NameError","evalue":"name 'train_df' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32m/home/sgarc/SemEval/semeval.ipynb Cell 26\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/sgarc/SemEval/semeval.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m train_df\n","\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"]}],"source":["train_df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","i = 62\n","# Elegir un hablante específico y sus valores\n","speaker1_data = lista[i][0]\n","speaker2_data = lista[i][1]\n","# Crear una secuencia de índices para el eje x\n","x = train_df['triggers'][i]\n","\n","# Crear una gráfica de líneas\n","plt.scatter( [i for i,x in enumerate(speaker1_data)],speaker1_data)\n","plt.scatter( [i for i,x in enumerate(speaker2_data)],speaker2_data)\n","plt.scatter( [i for i,x in enumerate(x)],x)\n","plt.xlabel('Índice')\n","plt.ylabel('Valor')\n","plt.title('Gráfica de Líneas del Hablante')\n","\n","# Mostrar la gráfica\n","plt.show()\n","print(speaker1_data, speaker2_data)"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"data":{"text/plain":["5"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["with open('train_df.pkl', 'rb') as file:\n","    train_df = pickle.load(file)\n","train_df['speakers'][0]"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-11-14T20:27:31.411474Z","iopub.status.busy":"2023-11-14T20:27:31.411122Z","iopub.status.idle":"2023-11-14T20:27:31.419834Z","shell.execute_reply":"2023-11-14T20:27:31.418827Z","shell.execute_reply.started":"2023-11-14T20:27:31.411447Z"},"trusted":true},"outputs":[],"source":["class SemEvalDataset(Dataset):\n","    def __init__(self, data):\n","        self.data = data\n","        self.len = len(self.data)\n","        print(list(train_df.columns))\n","        \n","    def __len__(self):\n","        return self.len\n","    \n","    def __getitem__(self, index):\n","        dict_x = {}\n","        dict_x['speaker'] = torch.tensor(self.data['speakers'][index], dtype=torch.int)\n","        dict_x['emotion'] = torch.tensor(self.data['emotions'][index], dtype=torch.int)\n","        dict_x['sentence_embeddings'] = torch.tensor(self.data['sentence_embeddings'][index], dtype=torch.float64)\n","        dict_x['valence'] = torch.tensor(self.data['valence'][index])\n","\n","        dict_y = {}\n","        dict_y['triggers'] =  torch.tensor(self.data['triggers'][index], dtype=torch.float32)\n","\n","        return dict_x, dict_y"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-11-14T20:27:34.333188Z","iopub.status.busy":"2023-11-14T20:27:34.332815Z","iopub.status.idle":"2023-11-14T20:27:34.338069Z","shell.execute_reply":"2023-11-14T20:27:34.337130Z","shell.execute_reply.started":"2023-11-14T20:27:34.333160Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["['episode', 'speakers', 'emotions', 'utterances', 'triggers', 'sentence_embeddings', 'valence', 'valence_speaker']\n"]}],"source":["train_dataset = SemEvalDataset(train_df)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-11-14T20:25:01.554296Z","iopub.status.busy":"2023-11-14T20:25:01.553658Z","iopub.status.idle":"2023-11-14T20:25:01.560760Z","shell.execute_reply":"2023-11-14T20:25:01.559810Z","shell.execute_reply.started":"2023-11-14T20:25:01.554264Z"},"trusted":true},"outputs":[{"data":{"text/plain":["[0.0, 0.125, 0.22333333333333336, 0.10114285714285713, 0.24]"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["train_df['valence'][9]"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-11-14T20:27:38.539944Z","iopub.status.busy":"2023-11-14T20:27:38.539550Z","iopub.status.idle":"2023-11-14T20:27:38.557326Z","shell.execute_reply":"2023-11-14T20:27:38.556432Z","shell.execute_reply.started":"2023-11-14T20:27:38.539912Z"},"trusted":true},"outputs":[{"data":{"text/plain":["({'speaker': tensor([1, 2, 1, 2, 1], dtype=torch.int32),\n","  'emotion': tensor([[0, 0, 0, 0, 1, 0, 0],\n","          [0, 0, 0, 0, 1, 0, 0],\n","          [0, 0, 0, 1, 0, 0, 0],\n","          [0, 0, 0, 0, 0, 1, 0],\n","          [0, 0, 0, 0, 0, 0, 1]], dtype=torch.int32),\n","  'sentence_embeddings': tensor([ 1.5435e-02,  1.9104e-01, -1.4461e-01,  1.5656e-01, -1.1302e-01,\n","           2.6897e-02,  3.4963e-01, -2.1497e-01, -2.7194e-01, -2.6170e-01,\n","           2.2691e-01,  2.5571e-01,  5.7965e-02, -2.9037e-01, -2.5372e-03,\n","          -1.6026e-01, -1.2177e-01, -2.8106e-01,  5.8836e-03,  3.4815e-02,\n","          -2.1617e-01, -4.5411e-01,  3.4106e-01, -8.1185e-02, -8.4146e-02,\n","           4.2784e-02,  1.8614e-01, -2.0929e-01, -3.5972e-02,  6.6583e-02,\n","          -5.6148e-01,  2.4411e-01, -5.5350e-01,  1.2666e-01,  1.6421e-01,\n","           1.8861e-01, -2.6305e-01,  2.7630e-03, -1.4858e-01, -1.5705e-01,\n","          -1.7093e-01,  3.0128e-01,  7.3719e-02,  3.1914e-01, -4.6498e-01,\n","          -1.6019e-01, -1.9618e-01,  4.6836e-02, -3.4160e-02,  6.0425e-02,\n","          -3.5195e-02, -2.6254e-01, -1.0699e-01, -4.2659e-01, -4.9854e-02,\n","           1.0745e-01,  2.8880e-01,  1.2351e-01, -4.1117e-01, -1.3592e-01,\n","           9.7562e-02,  2.8949e-02,  4.8366e-01,  2.3046e-01, -2.2441e-01,\n","           2.7998e-01, -1.3333e-01,  1.6697e-01, -2.7954e-01,  1.0675e-01,\n","           1.3142e-01,  2.8263e-01, -6.1820e-02, -1.8304e-02, -1.1976e-01,\n","          -1.1886e-01,  3.6339e-01,  2.9383e-01,  1.8289e-01, -8.5399e-02,\n","          -2.1336e-01, -9.6660e-02, -3.2534e-03, -5.3218e-02, -3.9423e-01,\n","          -2.3137e-02,  3.6797e-01,  1.0800e-01,  5.8996e-01, -3.0821e-01,\n","          -7.3996e-02, -4.7143e-01, -1.5482e-01, -1.6645e-01, -1.1626e-02,\n","           4.1171e-02, -1.5074e-01,  6.7733e-02, -2.5392e-02,  3.9660e-01,\n","          -3.4040e-01, -1.7292e-01,  4.7503e-01, -1.6035e-01,  2.2584e-02,\n","          -2.8723e-01, -1.1425e-01,  8.3175e-02,  1.8091e-01, -2.3736e-01,\n","          -3.4992e-01,  1.8530e-01,  2.0755e-03, -1.5066e-01, -4.3334e-02,\n","          -3.4536e-01, -4.1798e-01, -1.0007e-02,  1.5352e-01, -1.0618e-01,\n","          -3.0197e-02,  3.1533e-02,  2.4963e-01, -2.8668e-01,  3.1355e-01,\n","           7.8519e-02, -5.5124e-02, -5.0886e-01,  4.4597e-01, -4.5512e-02,\n","           2.3057e-01,  2.9733e-01,  1.7652e-01,  2.3015e-01, -2.2611e-01,\n","          -1.3433e-01, -5.5602e-02, -3.2439e-02, -3.6850e-01, -3.2950e-02,\n","          -3.8706e-01, -2.3565e-01,  1.5413e-01, -2.0037e-01,  1.6148e-01,\n","           8.2551e-03,  6.4377e-02, -4.2125e-01,  2.7163e-01, -2.1113e-01,\n","           1.0578e-01, -1.7155e-01, -1.3251e-01, -1.4326e-01,  2.2151e-01,\n","           1.0214e-01,  2.1038e-01, -4.6483e-02, -9.3774e-02,  8.2475e-02,\n","          -2.3463e-01,  8.0894e-02,  2.6076e-01,  6.4370e-02,  2.0823e-01,\n","           3.1318e-01, -2.3111e-01, -8.9434e-02, -5.1980e-02,  1.4328e-01,\n","          -2.6736e-01,  4.4934e-02, -1.4293e-01, -4.9882e-02, -4.6144e-01,\n","           1.9548e-01, -2.8561e-01,  8.0999e-02,  1.2164e-01,  3.4830e-01,\n","           6.1635e-02, -1.2783e-01, -2.4734e-01,  1.7405e-01,  1.4674e-01,\n","           3.2083e-03, -4.1461e-02,  2.6832e-01, -3.5925e-03, -1.4209e-01,\n","          -8.1487e-02, -4.1708e-01,  9.6754e-02, -1.4110e-01, -2.4285e-01,\n","          -8.1332e-02, -5.7924e-03,  2.3822e-01, -1.2731e-01,  5.9195e-01,\n","          -3.3653e-01, -1.0396e-01, -1.8358e-01, -3.5947e-02, -1.2538e-01,\n","          -4.1297e-01, -2.4509e-01, -3.8948e-01, -3.9172e-01,  6.0800e-02,\n","           1.7430e-01,  2.6013e-01, -2.4266e-01, -4.5345e-01,  1.0546e-01,\n","          -1.3831e-01,  9.7694e-02, -1.6048e-02, -9.8461e-02, -2.2315e-01,\n","           3.4807e-02, -1.8326e-01,  1.8987e-02, -2.0471e-01,  4.5059e-01,\n","          -1.3590e-01, -1.5687e-01,  1.6878e-01,  1.7394e-01, -2.1731e-01,\n","          -2.4600e-01, -3.3402e-01, -3.1993e-01, -2.9783e-01,  1.3283e-01,\n","           2.7896e-01, -1.3069e-01,  2.9881e-02,  2.0148e-01, -2.7877e-01,\n","           1.3232e-01,  1.0189e-01,  1.7260e-01, -5.9042e-02,  5.2092e-02,\n","          -2.6086e-01, -9.3937e-02, -1.7864e-01,  2.5968e-01, -1.3325e-01,\n","          -4.5945e-02, -9.1140e-03,  1.6650e-01,  1.1998e-01, -1.9498e-01,\n","          -2.2552e-01,  3.2901e-01, -1.9126e-01,  1.2904e-01, -1.8293e-01,\n","          -2.2409e-01, -9.5649e-02,  5.8114e-02,  6.1111e-02, -1.1188e-01,\n","          -2.0300e-01,  1.1504e-01, -5.5065e-01,  4.4185e-01,  3.1018e-01,\n","           4.5058e-02, -2.2974e-01, -1.8752e-01, -1.7857e-01, -4.2738e-01,\n","           3.3327e-01,  6.3845e-02, -1.6314e-02, -2.4689e-02, -9.1805e-02,\n","          -1.0726e-01,  3.2152e-01,  4.5983e-01, -2.2644e-01,  3.7498e-01,\n","          -5.9091e-02,  3.1420e-03,  2.1112e-01,  1.4641e-01,  2.8845e-01,\n","          -1.4297e-01, -2.9434e-01,  1.0957e-01, -3.8628e-01,  7.9673e-02,\n","           1.9792e-01, -5.4850e-02,  3.1324e-02,  7.0512e-03,  5.2801e-01,\n","           3.2228e-01, -6.0440e-02,  6.8027e-02,  2.5792e-01,  2.1023e-01,\n","          -4.0615e-01,  9.2278e-02,  3.1452e-01, -8.0324e-02, -6.2210e-01,\n","           2.3146e-01,  3.7975e-02, -1.3606e-01,  1.3269e-01, -2.7537e-01,\n","          -5.8938e-02, -3.8517e-01,  2.9018e-01,  2.3167e-01, -2.2929e-01,\n","          -6.7931e-02, -1.1203e-01,  4.9137e-01,  9.6465e-02, -1.3561e-01,\n","           1.8272e-01, -2.6119e-02, -3.7534e-01,  2.0224e-01,  7.1736e-02,\n","          -4.6109e-02,  4.5314e-01, -2.5361e-01,  2.6559e-01,  1.6390e-01,\n","           4.8228e-01,  3.1379e-01, -2.0351e-01, -7.9738e-02, -7.9043e-02,\n","          -7.0611e-02, -2.6820e-01,  7.7857e-02, -1.3212e-01, -2.1756e-01,\n","          -2.4547e-01, -1.1354e-01,  6.7133e-02,  2.2660e-01,  1.3489e-02,\n","          -2.6893e-02,  2.1151e-01, -3.3319e-01,  1.4682e-01,  2.4829e-02,\n","          -1.7845e-01, -1.4411e-01,  6.9425e-02, -2.7517e-01,  3.2644e-01,\n","          -6.7188e-02,  7.3571e-02,  1.1347e-01,  2.3784e-01,  1.5571e-01,\n","           4.1429e-01, -8.6976e-02,  4.2249e-01,  3.3863e-01, -3.2358e-02,\n","          -2.8767e-01,  2.9873e-01, -3.8234e-02,  4.3216e-01, -2.8369e-01,\n","          -6.1646e-02, -1.5792e-01,  1.4984e-01,  2.7489e-01, -1.1896e-01,\n","           2.8096e-01,  6.9045e-02,  1.5056e-01,  1.2398e-01,  8.6548e-02,\n","           1.5293e-01, -8.6047e-02,  4.1089e-01, -3.9179e-01,  2.8493e-01,\n","           6.3291e-02,  3.1727e-01, -2.1644e-01,  5.2294e-02, -2.1220e-01,\n","           5.9734e-02, -1.6797e-01,  7.4987e-02,  1.5756e-01,  2.6854e-02,\n","          -8.1559e-02,  1.9483e-01, -1.7788e-01,  3.0571e-01, -3.3686e-02,\n","          -2.6165e-01, -1.7709e-01,  6.6872e-02,  3.3977e-01,  1.8977e-01,\n","          -2.5328e-01,  1.4460e-01,  4.0149e-02, -6.6092e-02, -6.7821e-02,\n","           4.5862e-01, -1.4121e-01,  1.3958e-01, -7.0128e-03, -1.9152e-01,\n","           7.4626e-03, -1.5336e-01, -4.4545e-01,  2.2142e-01, -2.3417e-01,\n","          -2.2547e-01,  1.5266e-01,  2.1983e-01,  3.0813e-01, -2.3608e-02,\n","           9.9833e-02, -1.3240e-01, -3.0622e-01, -3.8713e-02, -1.5037e-01,\n","           5.2758e-03, -2.1292e-01, -5.4134e-02,  8.1767e-03,  2.3227e-01,\n","           9.0442e-02,  3.1807e-01, -2.4797e-01,  2.3265e-02,  7.0020e-02,\n","          -1.6621e-01,  8.3369e-02,  9.7116e-03,  5.7621e-02, -2.1573e-01,\n","           3.8063e-01, -3.9186e-02, -6.0016e-03,  3.1670e-01, -2.4325e-01,\n","           4.5739e-01,  2.2835e-02,  1.2813e-01, -2.4174e-02,  3.9127e-01,\n","          -5.9528e-01,  1.9972e-01,  2.5608e-01,  4.0404e-01, -2.1112e-01,\n","          -2.9508e-01, -1.4300e-02,  5.8063e-02,  7.2966e-02, -3.9089e-01,\n","          -2.3467e-01, -2.7674e-01, -3.4855e-01, -5.5141e-02, -3.8664e-01,\n","           1.7087e-01, -8.8823e-02,  2.9397e-01, -5.5948e-03,  3.7125e-01,\n","          -1.0177e-01,  1.2372e-03,  5.9060e-01, -9.0343e-02, -1.5538e-01,\n","           7.7644e-02,  3.4664e-01,  2.9254e-01,  4.2059e-02,  3.0205e-01,\n","          -3.4701e-01, -5.1816e-02,  1.1076e-01,  1.2048e-01, -1.7807e-01,\n","           2.7893e-01,  1.0996e-01,  2.7156e-01,  2.4492e-01, -1.1766e-01,\n","          -4.6778e-03, -1.4647e-01,  1.3310e-01,  1.2380e-01,  3.0001e-01,\n","           3.1073e-01, -7.2991e-02,  7.6213e-03, -8.3042e-02,  1.9681e-02,\n","          -3.3065e-01, -2.9651e-01, -6.0425e-02,  6.6367e-03, -8.7338e-02,\n","          -3.1793e-01, -4.2798e-01, -1.1249e-01,  2.8604e-01,  1.3570e-01,\n","           5.1616e-01, -1.5498e-01,  4.1921e-03, -1.1947e-01,  1.8300e-01,\n","           3.4067e-01, -1.0750e-01,  7.9312e-02,  3.8383e-01,  1.1481e-01,\n","           5.0200e-02,  4.6722e-02, -6.7184e-02, -3.6945e-02, -1.4855e-01,\n","          -8.7412e-02,  3.2582e-01, -2.7967e-01, -6.6737e-02,  5.1685e-04,\n","          -1.6115e-01, -3.6918e-02,  2.8746e-01, -6.7227e-04,  1.8304e-01,\n","           2.0920e-01, -4.5166e-01,  3.4570e-01, -3.0676e-01, -3.1477e-01,\n","           1.3313e-02,  3.3645e-01,  3.1487e-02,  2.9210e-01,  2.3737e-01,\n","          -2.4112e-01,  3.3327e-01, -1.4161e-01,  1.1568e-01,  1.5849e-01,\n","          -6.1750e-02,  3.1259e-01,  1.3754e-02, -1.9567e-01, -2.5832e-01,\n","          -2.7526e-01,  4.1912e-02,  1.7747e-02,  1.0553e-01, -3.3328e-01,\n","          -1.6363e-01,  1.3976e-01, -4.6187e-01, -1.7859e-01,  2.6980e-01,\n","          -1.6902e-02, -1.2642e-01, -2.6393e-01,  7.7405e-02, -1.8960e-01,\n","          -7.6250e-02, -4.1391e-01,  1.4410e-02, -7.4711e-02, -1.0104e-01,\n","          -2.7503e-01, -7.5351e-02, -8.3265e-02, -4.1815e-02, -9.0242e-02,\n","          -9.7362e-02, -1.6811e-01, -4.0691e-02, -7.8267e-02,  2.5095e-02,\n","          -3.5983e-01, -5.7223e-03,  1.9733e-01,  1.5846e-01, -1.8219e-01,\n","          -1.3842e-01, -2.6278e-01, -1.2114e-01,  3.5425e-01, -1.7423e-01,\n","           1.1002e-01, -3.5327e-02, -7.1690e-02, -1.1004e-01, -2.1094e-01,\n","           6.3590e-03,  9.6924e-03, -2.3140e-01,  4.7358e-02, -1.2091e-01,\n","          -2.1492e-01,  2.7851e-01,  3.4298e-01,  6.2459e-02,  1.5186e-01,\n","           1.8801e-01, -2.8747e-01,  1.5628e-01,  1.7638e-02, -1.1006e-01,\n","           1.3726e-01,  3.4202e-01, -1.9188e-01,  5.8576e-01,  2.6098e-01,\n","           1.4924e-01, -2.7028e-01,  4.1905e-02,  1.6354e-01,  2.0230e-01,\n","           2.5827e-01, -4.3530e-01, -8.8108e-02,  1.5027e-01, -7.9316e-02,\n","          -1.4020e-01, -3.3773e-01,  1.0908e-01, -2.8410e-01,  2.5871e-01,\n","          -8.9924e-02,  4.0039e-01,  1.3160e-02,  6.7415e-02,  1.0686e-01,\n","           1.3529e-01,  8.9333e-02, -2.3183e-01,  9.3499e-02, -9.5682e-03,\n","           5.1061e-02, -4.1683e-03, -1.0249e-01, -1.6296e-01, -2.6454e-01,\n","           4.3500e-01,  4.5636e-01, -5.5093e-02,  6.1371e-02,  1.9829e-01,\n","           3.6221e-02, -1.5665e-01, -4.2578e-01,  2.3910e-01, -4.0139e-01,\n","          -2.2127e-01, -2.8987e-01, -1.9839e-01, -1.1117e-01,  3.8733e-03,\n","           1.7012e-01,  4.1391e-02, -5.0711e-01, -1.9607e-01,  2.4841e-01,\n","          -3.8918e-01, -1.8573e-01, -7.9131e-02,  1.3666e-01,  1.1281e-01,\n","           2.5447e-01,  2.8637e-01, -2.0454e-01,  2.6724e-01,  1.2395e-01,\n","          -3.5391e-01,  3.0370e-01,  3.6211e-01, -1.8544e-01,  3.9592e-01,\n","           2.9729e-01,  3.4411e-01,  1.4173e-01,  2.7800e-01, -2.3383e-01,\n","           9.6886e-02,  7.5432e-02,  3.3256e-01,  2.5464e-01, -2.1043e-01,\n","           1.2023e-01, -3.5542e-02,  2.8011e-01,  3.8810e-01, -1.6717e-01,\n","           8.0157e-02,  4.4852e-02, -1.3652e-01,  1.5836e-01, -1.5495e-03,\n","          -2.9077e-02,  2.8139e-01,  1.2892e-02, -3.6947e-01, -1.9519e-02,\n","          -8.2490e-02, -6.8739e-02, -4.1270e-02, -1.1781e-01,  4.8043e-02,\n","          -1.2505e-01,  1.2737e-01, -3.3438e-01,  1.4835e-01, -3.3581e-02,\n","          -2.4411e-01, -7.2818e-02, -5.6814e-02,  3.1314e-01,  1.7248e-01,\n","           9.0162e-02, -1.7493e-01,  2.0817e-01, -1.0459e-01, -1.6693e-01,\n","          -2.3130e-01,  6.6805e-04,  1.7327e-02, -9.4656e-02,  1.2739e-01,\n","           2.1211e-01,  1.6039e-01, -3.0028e-01,  3.3175e-01, -4.2685e-01,\n","          -3.3640e-02, -3.7473e-02,  1.6924e-01,  1.2446e-01, -3.6620e-02,\n","          -1.1779e-01,  6.8507e-02, -2.1433e-01, -4.8806e-02, -2.6776e-01,\n","          -1.5968e-01,  1.1197e-01, -3.1603e-01,  3.6791e-02,  1.7434e-01,\n","           2.3750e-01,  4.6244e-01,  8.8068e-02], dtype=torch.float64),\n","  'valence': tensor([0.0000, 0.1250, 0.2233, 0.1011, 0.2400], dtype=torch.float64)},\n"," {'triggers': tensor([0., 0., 0., 1., 0.])})"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["train_dataset.__getitem__(9)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-11-14T20:28:14.534054Z","iopub.status.busy":"2023-11-14T20:28:14.533303Z","iopub.status.idle":"2023-11-14T20:28:14.541711Z","shell.execute_reply":"2023-11-14T20:28:14.540738Z","shell.execute_reply.started":"2023-11-14T20:28:14.534021Z"},"trusted":true},"outputs":[],"source":["class MELDCollate:\n","    def __init__(self, pad_value = 0):\n","        self.pad_value = pad_value\n","    def __call__(self, batch):\n","        speaker             = pad_sequence([item[0]['speaker'] for item in batch], batch_first = True)\n","        emotion             = pad_sequence([item[0]['emotion'] for item in batch], batch_first = True)\n","        sentence_embeddings = pad_sequence([item[0]['sentence_embeddings'] for item in batch], batch_first = True)\n","        valence             = pad_sequence([item[0]['valence'] for item in batch], batch_first = True)\n","        # print('\\noriginal list : ',[item[0]['speaker'] for item in batch], '\\n\\npadded list : ', speaker)\n","        labels              = pad_sequence([item[1]['triggers'] for item in batch], batch_first = True)\n","\n","        dict_x = { 'speaker': speaker, 'emotion':emotion,  'sentence_embeddings':sentence_embeddings, 'valence':valence}\n","        dict_y = {'labels': labels}\n","\n","        return dict_x, dict_y"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-11-15T01:15:44.716112Z","iopub.status.busy":"2023-11-15T01:15:44.715450Z","iopub.status.idle":"2023-11-15T01:15:44.741037Z","shell.execute_reply":"2023-11-15T01:15:44.739996Z","shell.execute_reply.started":"2023-11-15T01:15:44.716079Z"},"trusted":true},"outputs":[],"source":["train_loader  = DataLoader(dataset = train_dataset, batch_size = 64, shuffle=True, collate_fn= MELDCollate())"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-11-15T01:15:40.470064Z","iopub.status.busy":"2023-11-15T01:15:40.469677Z","iopub.status.idle":"2023-11-15T01:15:40.501160Z","shell.execute_reply":"2023-11-15T01:15:40.499947Z","shell.execute_reply.started":"2023-11-15T01:15:40.470038Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Batch 6:\n","({'speaker': tensor([[1, 2, 3,  ..., 0, 0, 0],\n","        [1, 1, 0,  ..., 0, 0, 0],\n","        [1, 2, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 2, 3,  ..., 0, 0, 0],\n","        [1, 2, 1,  ..., 0, 0, 0],\n","        [1, 2, 1,  ..., 0, 0, 0]], dtype=torch.int32), 'emotion': tensor([[[0, 0, 0,  ..., 1, 0, 0],\n","         [0, 0, 0,  ..., 1, 0, 0],\n","         [0, 0, 0,  ..., 1, 0, 0],\n","         ...,\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0]],\n","\n","        [[1, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         ...,\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0]],\n","\n","        [[0, 0, 0,  ..., 0, 0, 1],\n","         [0, 0, 0,  ..., 0, 0, 1],\n","         [0, 0, 0,  ..., 0, 0, 1],\n","         ...,\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0]],\n","\n","        ...,\n","\n","        [[0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 1, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         ...,\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0]],\n","\n","        [[0, 0, 0,  ..., 0, 1, 0],\n","         [1, 0, 0,  ..., 0, 0, 0],\n","         [1, 0, 0,  ..., 0, 0, 0],\n","         ...,\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0]],\n","\n","        [[0, 0, 0,  ..., 1, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 1],\n","         [0, 0, 0,  ..., 1, 0, 0],\n","         ...,\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0]]], dtype=torch.int32), 'sentence_embeddings': tensor([[ 0.0148,  0.1619, -0.1450,  ...,  0.2485,  0.4606,  0.0839],\n","        [ 0.0355,  0.1595, -0.1370,  ...,  0.2636,  0.4546,  0.0734],\n","        [ 0.0104,  0.1523, -0.1425,  ...,  0.2445,  0.4558,  0.0754],\n","        ...,\n","        [ 0.0112,  0.1302, -0.1527,  ...,  0.2617,  0.4411,  0.0772],\n","        [ 0.0088,  0.1398, -0.1419,  ...,  0.2592,  0.4580,  0.1038],\n","        [ 0.0148,  0.1619, -0.1450,  ...,  0.2485,  0.4606,  0.0839]],\n","       dtype=torch.float64), 'valence': tensor([[0.2616, 0.1881, 0.2646,  ..., 0.0000, 0.0000, 0.0000],\n","        [0.2052, 0.3375, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n","        [0.3243, 0.0000, 0.2423,  ..., 0.0000, 0.0000, 0.0000],\n","        ...,\n","        [0.1604, 0.0849, 0.3197,  ..., 0.0000, 0.0000, 0.0000],\n","        [0.0906, 0.2066, 0.1615,  ..., 0.0000, 0.0000, 0.0000],\n","        [0.2467, 0.0000, 0.2050,  ..., 0.0000, 0.0000, 0.0000]],\n","       dtype=torch.float64)}, {'labels': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 1., 0.,  ..., 0., 0., 0.],\n","        [1., 0., 1.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]])})\n"]}],"source":["desired_batch_index = 6\n","for i, batch in enumerate(train_loader):\n","    if i == desired_batch_index:\n","        # 'batch' contendrá el batch en el índice especificado\n","        print(f\"Batch {i}:\")\n","        print(batch)\n","        break"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[0.0, 0.125, 0.22333333333333336, 0.10114285714285713, 0.24] [0      False\n","1      False\n","2      False\n","3      False\n","4      False\n","       ...  \n","226    False\n","227    False\n","228    False\n","229    False\n","230    False\n","Name: Chandler, Length: 231, dtype: bool, 0      False\n","1      False\n","2      False\n","3      False\n","4      False\n","       ...  \n","226    False\n","227    False\n","228    False\n","229    False\n","230    False\n","Name: Monica, Length: 231, dtype: bool, 0      False\n","1      False\n","2      False\n","3      False\n","4      False\n","       ...  \n","226    False\n","227    False\n","228    False\n","229    False\n","230    False\n","Name: Chandler, Length: 231, dtype: bool, 0      False\n","1      False\n","2      False\n","3      False\n","4      False\n","       ...  \n","226    False\n","227    False\n","228    False\n","229    False\n","230    False\n","Name: Monica, Length: 231, dtype: bool, 0      False\n","1      False\n","2      False\n","3      False\n","4      False\n","       ...  \n","226    False\n","227    False\n","228    False\n","229    False\n","230    False\n","Name: Chandler, Length: 231, dtype: bool]\n"]},{"data":{"text/plain":["tensor([0., 0., 0., 0., 0.])"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["input_seq = train_df['valence'][9]\n","speakers_spcf = train_df['speakers'][9]\n","print(input_seq, speakers_spcf)\n","torch.zeros(len(input_seq))"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":2488965,"sourceId":4222789,"sourceType":"datasetVersion"},{"datasetId":3829061,"sourceId":6632753,"sourceType":"datasetVersion"}],"dockerImageVersionId":30559,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
